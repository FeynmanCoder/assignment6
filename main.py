"""
è®ºæ–‡é˜…è¯»Agent - ç”¨äºåˆ†æè®ºæ–‡å¹¶å­¦ä¹ è®ºæ–‡å†™ä½œ
æ”¯æŒå¤šç§LLMæä¾›å•†ï¼ˆOpenAIã€Geminiç­‰ï¼‰
"""

import os
from typing import Optional, List, Dict
from abc import ABC, abstractmethod
import json
from pathlib import Path

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()  # è‡ªåŠ¨åŠ è½½.envæ–‡ä»¶
except ImportError:
    pass  # å¦‚æœæ²¡æœ‰å®‰è£…python-dotenvï¼Œè·³è¿‡


class LLMProvider(ABC):
    """LLMæä¾›å•†çš„æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤"""
        pass


class OpenAIProvider(LLMProvider):
    """OpenAI (ChatGPT) æä¾›å•†"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4o-mini", base_url: Optional[str] = None):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.base_url = base_url or os.getenv("OPENAI_BASE_URL")
        self.model = model
        
        if not self.api_key:
            raise ValueError("éœ€è¦æä¾›OpenAI APIå¯†é’¥")
        
        try:
            from openai import OpenAI
            # åˆ›å»ºå®¢æˆ·ç«¯ï¼Œæ”¯æŒè‡ªå®šä¹‰base_url
            client_kwargs = {"api_key": self.api_key}
            if self.base_url:
                client_kwargs["base_url"] = self.base_url
            self.client = OpenAI(**client_kwargs)
        except ImportError:
            raise ImportError("è¯·å®‰è£…openaiåº“: pip install openai")
    
    def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """å‘é€æ¶ˆæ¯åˆ°OpenAIå¹¶è·å–å›å¤"""
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            **kwargs
        )
        return response.choices[0].message.content


class GeminiProvider(LLMProvider):
    """Google Gemini æä¾›å•†"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gemini-pro"):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        self.model = model
        if not self.api_key:
            raise ValueError("éœ€è¦æä¾›Gemini APIå¯†é’¥")
        
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            self.client = genai.GenerativeModel(self.model)
        except ImportError:
            raise ImportError("è¯·å®‰è£…google-generativeaiåº“: pip install google-generativeai")
    
    def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """å‘é€æ¶ˆæ¯åˆ°Geminiå¹¶è·å–å›å¤"""
        # å°†OpenAIæ ¼å¼çš„æ¶ˆæ¯è½¬æ¢ä¸ºGeminiæ ¼å¼
        prompt_parts = []
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            if role == "system":
                prompt_parts.append(f"System: {content}")
            elif role == "user":
                prompt_parts.append(f"User: {content}")
            elif role == "assistant":
                prompt_parts.append(f"Assistant: {content}")
        
        prompt = "\n\n".join(prompt_parts)
        response = self.client.generate_content(prompt)
        return response.text


class PDFConverter:
    """å°†PDFè½¬æ¢ä¸ºMarkdownçš„è½¬æ¢å™¨"""
    
    def __init__(self, use_mineru: bool = False, mineru_token: Optional[str] = None):
        """
        åˆå§‹åŒ–PDFè½¬æ¢å™¨
        
        Args:
            use_mineru: æ˜¯å¦ä½¿ç”¨MinerU APIï¼ˆæ›´å¥½åœ°æ”¯æŒå›¾ç‰‡å’Œå…¬å¼ï¼‰
            mineru_token: MinerU API tokenï¼ˆå¯ä»ç¯å¢ƒå˜é‡MINERU_TOKENè¯»å–ï¼‰
        """
        self.use_mineru = use_mineru
        self.mineru_token = mineru_token or os.getenv('MINERU_TOKEN')
        
        if use_mineru and not self.mineru_token:
            print("è­¦å‘Š: æœªæä¾›MinerU tokenï¼Œå°†å›é€€åˆ°pymupdf4llm")
            self.use_mineru = False
    
    def convert_to_markdown(self, pdf_path: str, output_dir: Optional[str] = None) -> str:
        """
        å°†PDFè½¬æ¢ä¸ºMarkdownï¼ˆæ”¯æŒå›¾ç‰‡å’Œå…¬å¼æå–ï¼‰
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨PDFåŒç›®å½•
            
        Returns:
            è½¬æ¢åçš„markdownæ–‡ä»¶è·¯å¾„
        """
        pdf_path = Path(pdf_path)
        if not pdf_path.exists():
            raise FileNotFoundError(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if output_dir:
            output_path = Path(output_dir) / f"{pdf_path.stem}.md"
            output_path.parent.mkdir(parents=True, exist_ok=True)
        else:
            output_path = pdf_path.with_suffix('.md')
        
        # å¦‚æœå·²å­˜åœ¨è½¬æ¢ç»“æœï¼Œè·³è¿‡è½¬æ¢
        if output_path.exists():
            print(f"âš ï¸  å·²å­˜åœ¨Markdownæ–‡ä»¶ï¼Œè·³è¿‡è½¬æ¢: {output_path}")
            print(f"æç¤ºï¼šå¦‚éœ€é‡æ–°è½¬æ¢ï¼Œè¯·åˆ é™¤outputæ–‡ä»¶å¤¹æˆ–è¯¥æ–‡ä»¶")
            return str(output_path)
        
        # å°è¯•ä½¿ç”¨MinerU APIï¼ˆæ›´å¥½çš„å›¾ç‰‡å’Œå…¬å¼æ”¯æŒï¼‰
        if self.use_mineru:
            print(f"ğŸ“¡ ä½¿ç”¨MinerU APIè½¬æ¢PDFï¼ˆæ”¯æŒå›¾ç‰‡å’Œå…¬å¼ï¼‰...")
            try:
                return self._convert_with_mineru(pdf_path, output_path)
            except Exception as e:
                print(f"âŒ MinerUè½¬æ¢å¤±è´¥ï¼Œå›é€€åˆ°pymupdf4llm: {e}")
        else:
            print(f"âš¡ ä½¿ç”¨pymupdf4llmå¿«é€Ÿè½¬æ¢...")
        
        # ä½¿ç”¨pymupdf4llmä½œä¸ºå¤‡é€‰
        return self._convert_with_pymupdf(pdf_path, output_path)
    
    def _convert_with_mineru(self, pdf_path: Path, output_path: Path) -> str:
        """ä½¿ç”¨MinerU APIè½¬æ¢ï¼ˆæ”¯æŒå›¾ç‰‡å’Œå…¬å¼ï¼‰"""
        import requests
        import uuid
        import time
        import zipfile
        import shutil
        
        header = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.mineru_token}"
        }
        
        # 1. ç”³è¯·ä¸Šä¼ URL
        url = "https://mineru.net/api/v4/file-urls/batch"
        data = {
            "enable_formula": True,  # å¯ç”¨å…¬å¼è¯†åˆ«
            "enable_table": True,
            "model_version": "vlm",
            "files": [{"name": pdf_path.name, "data_id": str(uuid.uuid4())}]
        }
        
        response = requests.post(url, headers=header, json=data)
        response.raise_for_status()
        result = response.json()
        
        if result.get("code") != 0:
            raise Exception(f"ç”³è¯·ä¸Šä¼ å¤±è´¥: {result}")
        
        batch_id = result["data"]["batch_id"]
        upload_url = result["data"]["file_urls"][0]
        
        # 2. ä¸Šä¼ PDF
        print(f"ğŸ“¤ æ­£åœ¨ä¸Šä¼ PDFæ–‡ä»¶...")
        with open(pdf_path, 'rb') as f:
            upload_response = requests.put(upload_url, data=f)
            upload_response.raise_for_status()
        
        print(f"âœ… ä¸Šä¼ æˆåŠŸï¼æ‰¹æ¬¡ID: {batch_id}")
        print(f"â³ ç­‰å¾…MinerUå¤„ç†ï¼ˆå¯èƒ½éœ€è¦1-3åˆ†é’Ÿï¼‰...")
        
        # 3. è½®è¯¢ç»“æœ
        retrieve_url = f"https://mineru.net/api/v4/extract-results/batch/{batch_id}"
        max_retry = 180
        retry = 0
        
        while retry < max_retry:
            time.sleep(3)
            res = requests.get(retrieve_url, headers=header)
            res.raise_for_status()
            payload = res.json()
            results = payload.get("data", {}).get("extract_result", [])
            
            if results and results[0].get("state") == "done":
                zip_url = results[0].get("full_zip_url")
                if not zip_url:
                    raise Exception("æœªè·å–åˆ°ä¸‹è½½é“¾æ¥")
                
                print(f"âœ… MinerUå¤„ç†å®Œæˆï¼Œæ­£åœ¨ä¸‹è½½ç»“æœ...")
                
                # 4. ä¸‹è½½å¹¶è§£å‹ç»“æœ
                zip_path = output_path.with_suffix('.zip')
                response = requests.get(zip_url, stream=True)
                response.raise_for_status()
                
                with open(zip_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                
                # 5. è§£å‹å¹¶æå–markdown
                with zipfile.ZipFile(zip_path, 'r') as zf:
                    # æå–full.md
                    if 'full.md' in zf.namelist():
                        with zf.open('full.md') as src:
                            with open(output_path, 'wb') as dst:
                                shutil.copyfileobj(src, dst)
                    
                    # æå–imagesæ–‡ä»¶å¤¹
                    images_dir = output_path.parent / "images"
                    images_dir.mkdir(exist_ok=True)
                    for member in zf.namelist():
                        if member.startswith('images/'):
                            zf.extract(member, output_path.parent)
                
                print(f"PDFå·²è½¬æ¢ä¸ºMarkdownï¼ˆå«å›¾ç‰‡å’Œå…¬å¼ï¼‰: {output_path}")
                return str(output_path)
            
            retry += 1
            if retry % 10 == 0:
                print(f"ç­‰å¾…è½¬æ¢å®Œæˆ... ({retry}/{max_retry})")
        
        raise Exception("è½¬æ¢è¶…æ—¶")
    
    def _convert_with_pymupdf(self, pdf_path: Path, output_path: Path) -> str:
        """ä½¿ç”¨pymupdf4llmè½¬æ¢ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰"""
        try:
            import pymupdf4llm
        except ImportError:
            raise ImportError("è¯·å®‰è£…pymupdf4llmåº“: pip install pymupdf4llm")
        
        # è½¬æ¢PDFåˆ°markdown
        md_text = pymupdf4llm.to_markdown(str(pdf_path))
        
        # ä¿å­˜markdownæ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(md_text)
        
        print(f"PDFå·²è½¬æ¢ä¸ºMarkdown: {output_path}")
        return str(output_path)


class PaperAnalyzer:
    """è®ºæ–‡åˆ†æå™¨ - æ ¸å¿ƒç±»"""
    
    @staticmethod
    def extract_images_from_markdown(markdown_path: Path) -> List[Path]:
        """ä»markdownæ–‡ä»¶ä¸­æå–å›¾ç‰‡è·¯å¾„"""
        import re
        
        with open(markdown_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åŒ¹é… ![...](images/xxx.png) æ ¼å¼
        image_pattern = r'!\[.*?\]\((images/[^)]+)\)'
        image_refs = re.findall(image_pattern, content)
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        base_dir = markdown_path.parent
        image_paths = []
        for ref in image_refs:
            img_path = base_dir / ref
            if img_path.exists():
                image_paths.append(img_path)
        
        return image_paths
    
    @staticmethod
    def image_to_base64(image_path: Path) -> str:
        """å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64ç¼–ç """
        import base64
        
        with open(image_path, 'rb') as f:
            image_data = f.read()
        
        # è·å–å›¾ç‰‡æ ¼å¼
        ext = image_path.suffix.lower().lstrip('.')
        if ext == 'jpg':
            ext = 'jpeg'
        
        base64_str = base64.b64encode(image_data).decode('utf-8')
        return f"data:image/{ext};base64,{base64_str}"
    
    # è®ºæ–‡åˆ†æé—®é¢˜æ¨¡æ¿
    ANALYSIS_QUESTIONS = [
        {
            "category": "åŸºæœ¬ä¿¡æ¯",
            "questions": [
                "è¿™ç¯‡è®ºæ–‡å‘è¡¨åœ¨ä»€ä¹ˆå¹³å°ï¼ˆæœŸåˆŠæˆ–ä¼šè®®ï¼‰ï¼Ÿè¯¥å¹³å°åœ¨è¯¥é¢†åŸŸçš„æƒå¨æ€§å¦‚ä½•ï¼Ÿ",
                "è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦åˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿä¸ç°æœ‰å·¥ä½œç›¸æ¯”æœ‰å“ªäº›çªç ´ï¼Ÿ",
            ]
        },
        {
            "category": "è®ºæ–‡ç»“æ„ä¸å†™ä½œ",
            "questions": [
                "è¿™ç¯‡è®ºæ–‡å±•ç°äº†ç ”ç©¶å·¥ä½œçš„å“ªäº›æ–¹é¢ï¼ˆå¦‚é—®é¢˜å®šä¹‰ã€æ–¹æ³•è®¾è®¡ã€å®éªŒéªŒè¯ã€ç»“æœåˆ†æç­‰ï¼‰ï¼Ÿ",
                "ä½œè€…æ˜¯å¦‚ä½•å®‰æ’è¿™äº›æ–¹é¢çš„å…ˆåé¡ºåºçš„ï¼Ÿå®ƒä»¬ä¹‹é—´çš„é€»è¾‘å…³è”æ˜¯å¦‚ä½•æ’å¸ƒçš„ï¼Ÿ",
                "è®ºæ–‡æ¯ä¸ªç« èŠ‚çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿç« èŠ‚ä¹‹é—´å¦‚ä½•è¿‡æ¸¡å’Œè¡”æ¥ï¼Ÿ",
                "è®ºæ–‡çš„æ‘˜è¦å’Œç»“è®ºåˆ†åˆ«å¼ºè°ƒäº†å“ªäº›å†…å®¹ï¼Ÿå®ƒä»¬å¦‚ä½•å‘¼åº”ï¼Ÿ",
            ]
        },
        {
            "category": "å›¾è¡¨åˆ†æ",
            "questions": [
                "è®ºæ–‡åŒ…å«å“ªäº›å›¾ç‰‡å’Œè¡¨æ ¼ï¼Ÿæ¯ä¸ªå›¾è¡¨åˆ†åˆ«ä»‹ç»äº†è®ºæ–‡å·¥ä½œçš„å“ªäº›æ–¹é¢ï¼Ÿ",
                "è¿™äº›å›¾è¡¨åœ¨è®ºæ–‡ä¸­çš„ä½ç½®å¦‚ä½•å®‰æ’ï¼Ÿå®ƒä»¬å¦‚ä½•ä¸æ–‡å­—å†…å®¹ç›¸å…³è”ï¼Ÿ",
                "å“ªäº›å›¾è¡¨æœ€èƒ½ä½“ç°è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®å’Œåˆ›æ–°ç‚¹ï¼Ÿ",
                "å›¾è¡¨çš„è®¾è®¡ï¼ˆå¦‚é…è‰²ã€å¸ƒå±€ã€æ ‡æ³¨ï¼‰æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿå®ƒä»¬å¦‚ä½•å¸®åŠ©è¯»è€…ç†è§£å†…å®¹ï¼Ÿ",
            ]
        },
        {
            "category": "å†™ä½œå»ºè®®",
            "questions": [
                "å¦‚æœæˆ‘è¦å‘è¡¨ç±»ä¼¼çš„å·¥ä½œï¼Œåº”è¯¥å¦‚ä½•ç»„ç»‡è®ºæ–‡ç»“æ„ï¼Ÿ",
                "æˆ‘åº”è¯¥åœ¨è®ºæ–‡ä¸­é‡ç‚¹å‘ˆç°å“ªäº›å·¥ä½œå†…å®¹ï¼Ÿå“ªäº›å†…å®¹éœ€è¦è¯¦ç»†æè¿°ï¼Œå“ªäº›å¯ä»¥ç®€ç•¥ï¼Ÿ",
                "æˆ‘åº”è¯¥æŠŠå“ªäº›å·¥ä½œé€šè¿‡å›¾ç‰‡æˆ–è¡¨æ ¼å‘ˆç°å‡ºæ¥ï¼Ÿå¦‚ä½•è®¾è®¡è¿™äº›å›¾è¡¨ï¼Ÿ",
                "è®ºæ–‡çš„è¯­è¨€è¡¨è¾¾æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿå¦‚ä½•ä¿æŒå­¦æœ¯æ€§çš„åŒæ—¶æé«˜å¯è¯»æ€§ï¼Ÿ",
                "è¿™ç¯‡è®ºæ–‡åœ¨å†™ä½œä¸Šæœ‰å“ªäº›å€¼å¾—å­¦ä¹ çš„åœ°æ–¹ï¼Ÿåˆæœ‰å“ªäº›å¯ä»¥æ”¹è¿›çš„åœ°æ–¹ï¼Ÿ",
            ]
        }
    ]
    
    def __init__(self, llm_provider: LLMProvider):
        self.llm = llm_provider
        self.analysis_results = {}
    
    def analyze_paper(self, markdown_path: str) -> Dict[str, any]:
        """
        åˆ†æè®ºæ–‡å¹¶å›ç­”æ‰€æœ‰é—®é¢˜
        
        Args:
            markdown_path: è®ºæ–‡markdownæ–‡ä»¶è·¯å¾„
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # è¯»å–è®ºæ–‡å†…å®¹
        md_path = Path(markdown_path)
        with open(md_path, 'r', encoding='utf-8') as f:
            paper_content = f.read()
        
        # æå–å›¾ç‰‡
        image_paths = self.extract_images_from_markdown(md_path)
        print(f"å¼€å§‹åˆ†æè®ºæ–‡...")
        print(f"è®ºæ–‡å­—æ•°: {len(paper_content)}")
        print(f"è®ºæ–‡å›¾ç‰‡æ•°: {len(image_paths)}")
        
        results = {
            "paper_path": markdown_path,
            "categories": []
        }
        
        # å¯¹æ¯ä¸ªç±»åˆ«çš„é—®é¢˜è¿›è¡Œåˆ†æ
        for category_info in self.ANALYSIS_QUESTIONS:
            category = category_info["category"]
            questions = category_info["questions"]
            
            print(f"\nåˆ†æç±»åˆ«: {category}")
            category_result = {
                "category": category,
                "qa_pairs": []
            }
            
            for i, question in enumerate(questions, 1):
                print(f"  é—®é¢˜ {i}/{len(questions)}: {question[:50]}...")
                
                # æ ¹æ®ç±»åˆ«é€‰æ‹©ä¸åŒçš„æç¤ºè¯ç­–ç•¥
                if category == "åŸºæœ¬ä¿¡æ¯":
                    # åŸºæœ¬ä¿¡æ¯ç±»ï¼šä¸¥æ ¼ç²¾ç®€
                    requirement = "è¦æ±‚ï¼š2-3ä¸ªè¦ç‚¹ï¼Œæ¯ç‚¹ä¸è¶…è¿‡20å­—ï¼Œæ€»å…±<60å­—ã€‚"
                    system_prompt = """ä½ æ˜¯è®ºæ–‡åˆ†æä¸“å®¶ã€‚å›ç­”å¿…é¡»æç®€ï¼š

ä¸¥æ ¼è¦æ±‚ï¼š
1. åªç”¨è¦ç‚¹åˆ—è¡¨ï¼Œä¸ç”¨æ®µè½
2. 2-3ä¸ªè¦ç‚¹ï¼Œæ¯ä¸ªä¸è¶…è¿‡20å­—
3. ç›´æ¥ç»™ç»“è®ºï¼Œä¸è¦è§£é‡Šè¿‡ç¨‹
4. ç”¨æ•°æ®/åè¯è€Œéæè¿°
5. æ€»å­—æ•°<60å­—
6. å¦‚æœçœ‹åˆ°å›¾ç‰‡ï¼Œä¼˜å…ˆåˆ†æå›¾ç‰‡å†…å®¹"""
                else:
                    # å…¶ä»–ç±»åˆ«ï¼šå®½æ¾é™åˆ¶ï¼Œä½†è¦æ±‚ç®€æ´
                    requirement = "è¦æ±‚ï¼š10ä¸ªè¦ç‚¹ä»¥å†…ï¼Œæ¯ä¸ªè¦ç‚¹ä¸è¶…è¿‡100å­—ã€‚è¯·ä½ å°½å¯èƒ½ç®€æ´åœ°å›ç­”ï¼Œåˆ‡ä¸­è¦ç‚¹ï¼Œä¸è¦æœ‰å†—ä½™çš„è¡¨è¾¾ã€‚"
                    system_prompt = """ä½ æ˜¯è®ºæ–‡åˆ†æä¸“å®¶ã€‚å›ç­”è¦ç®€æ´æ˜äº†ï¼š

è¦æ±‚ï¼š
1. ä½¿ç”¨è¦ç‚¹åˆ—è¡¨å½¢å¼ï¼Œé€»è¾‘æ¸…æ™°
2. æœ€å¤š10ä¸ªè¦ç‚¹ï¼Œæ¯ä¸ªè¦ç‚¹ä¸è¶…è¿‡100å­—
3. åˆ‡ä¸­è¦ç‚¹ï¼Œé¿å…å†—ä½™è¡¨è¾¾
4. ç»“åˆè®ºæ–‡çš„å…·ä½“å†…å®¹å’Œå›¾ç‰‡è¿›è¡Œåˆ†æ
5. ç”¨å…·ä½“çš„æ•°æ®ã€æ–¹æ³•åã€ç« èŠ‚åç­‰å®è´¨æ€§ä¿¡æ¯
6. å¦‚æœçœ‹åˆ°å›¾ç‰‡ï¼Œä¼˜å…ˆåˆ†æå›¾ç‰‡ä¼ è¾¾çš„æ ¸å¿ƒä¿¡æ¯"""
                
                # æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
                user_content = [
                    {
                        "type": "text",
                        "text": f"""{paper_content}

é—®é¢˜ï¼š{question}

{requirement}"""
                    }
                ]
                
                # æ·»åŠ å›¾ç‰‡ï¼ˆé™åˆ¶å‰5å¼ ï¼Œé¿å…tokenè¿‡å¤šï¼‰
                for img_path in image_paths[:5]:
                    try:
                        base64_image = self.image_to_base64(img_path)
                        user_content.append({
                            "type": "image_url",
                            "image_url": {"url": base64_image}
                        })
                    except Exception as e:
                        print(f"    è­¦å‘Š: æ— æ³•åŠ è½½å›¾ç‰‡ {img_path.name}: {e}")
                
                # æ„å»ºæ¶ˆæ¯
                messages = [
                    {
                        "role": "system",
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": user_content
                    }
                ]
                
                # è·å–LLMå›ç­”
                answer = self.llm.chat(messages)
                
                category_result["qa_pairs"].append({
                    "question": question,
                    "answer": answer
                })
            
            results["categories"].append(category_result)
        
        self.analysis_results = results
        return results
    
    def save_analysis_report(self, output_path: str) -> str:
        """
        å°†åˆ†æç»“æœä¿å­˜ä¸ºMarkdownæŠ¥å‘Š
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if not self.analysis_results:
            raise ValueError("æ²¡æœ‰å¯ä¿å­˜çš„åˆ†æç»“æœï¼Œè¯·å…ˆè¿è¡Œanalyze_paper()")
        
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# è®ºæ–‡åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**åˆ†æè®ºæ–‡**: {self.analysis_results['paper_path']}\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {self._get_current_time()}\n\n")
            f.write("---\n\n")
            
            for category_result in self.analysis_results["categories"]:
                category = category_result["category"]
                f.write(f"## {category}\n\n")
                
                for qa_pair in category_result["qa_pairs"]:
                    question = qa_pair["question"]
                    answer = qa_pair["answer"]
                    
                    f.write(f"### {question}\n\n")
                    f.write(f"{answer}\n\n")
                    f.write("---\n\n")
        
        print(f"\nåˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        return str(output_path)
    
    @staticmethod
    def _get_current_time() -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


class PaperReadingAgent:
    """è®ºæ–‡é˜…è¯»Agent - ä¸»å…¥å£ç±»"""
    
    def __init__(self, llm_provider: str = "openai", use_mineru: bool = True, **llm_kwargs):
        """
        åˆå§‹åŒ–è®ºæ–‡é˜…è¯»Agent
        
        Args:
            llm_provider: LLMæä¾›å•† ("openai" æˆ– "gemini")
            use_mineru: æ˜¯å¦ä½¿ç”¨MinerU APIè½¬æ¢PDFï¼ˆæ›´å¥½çš„å›¾ç‰‡å’Œå…¬å¼æ”¯æŒï¼‰
            **llm_kwargs: LLMæä¾›å•†çš„é¢å¤–å‚æ•°
        """
        # åˆå§‹åŒ–LLM
        if llm_provider.lower() == "openai":
            self.llm = OpenAIProvider(**llm_kwargs)
        elif llm_provider.lower() == "gemini":
            self.llm = GeminiProvider(**llm_kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {llm_provider}")
        
        # åˆå§‹åŒ–PDFè½¬æ¢å™¨å’Œè®ºæ–‡åˆ†æå™¨
        self.pdf_converter = PDFConverter(use_mineru=use_mineru)
        self.analyzer = PaperAnalyzer(self.llm)
    
    def process_paper(self, pdf_path: str, output_dir: Optional[str] = None) -> str:
        """
        å¤„ç†è®ºæ–‡çš„å®Œæ•´æµç¨‹
        
        Args:
            pdf_path: PDFè®ºæ–‡è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            åˆ†ææŠ¥å‘Šçš„è·¯å¾„
        """
        print("=" * 60)
        print("è®ºæ–‡é˜…è¯»Agent - å¼€å§‹å¤„ç†")
        print("=" * 60)
        
        # æ­¥éª¤1: è½¬æ¢PDFåˆ°Markdown
        print("\næ­¥éª¤1: è½¬æ¢PDFåˆ°Markdown...")
        markdown_path = self.pdf_converter.convert_to_markdown(pdf_path, output_dir)
        
        # æç¤ºç”¨æˆ·æ£€æŸ¥markdownæ–‡ä»¶
        print("\n" + "=" * 60)
        print(f"âœ… Markdownè½¬æ¢å®Œæˆï¼š{markdown_path}")
        print("\næ‚¨å¯ä»¥å…ˆæ£€æŸ¥è½¬æ¢ç»“æœï¼š")
        print(f"  - Markdownæ–‡ä»¶: {markdown_path}")
        if Path(markdown_path).parent.joinpath('images').exists():
            print(f"  - å›¾ç‰‡æ–‡ä»¶å¤¹: {Path(markdown_path).parent / 'images'}")
        print("\næŒ‰å›è½¦é”®ç»§ç»­åˆ†æï¼Œæˆ– Ctrl+C ä¸­æ­¢...")
        print("=" * 60)
        try:
            input()
        except KeyboardInterrupt:
            print("\n\nå·²å–æ¶ˆåˆ†æ")
            return markdown_path
        
        # æ­¥éª¤2: åˆ†æè®ºæ–‡
        print("\næ­¥éª¤2: åˆ†æè®ºæ–‡...")
        self.analyzer.analyze_paper(markdown_path)
        
        # æ­¥éª¤3: ç”ŸæˆæŠ¥å‘Š
        print("\næ­¥éª¤3: ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        pdf_name = Path(pdf_path).stem
        if output_dir:
            report_path = Path(output_dir) / f"{pdf_name}_analysis.md"
        else:
            report_path = Path(pdf_path).parent / f"{pdf_name}_analysis.md"
        
        report_path = self.analyzer.save_analysis_report(str(report_path))
        
        print("\n" + "=" * 60)
        print("å¤„ç†å®Œæˆï¼")
        print("=" * 60)
        print(f"Markdownæ–‡ä»¶: {markdown_path}")
        print(f"åˆ†ææŠ¥å‘Š: {report_path}")
        
        return report_path
    
    def batch_process_papers(self, papers_dir: str = "papers", output_dir: str = "output") -> List[str]:
        """
        æ‰¹é‡å¤„ç†papersæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰PDFè®ºæ–‡
        
        Args:
            papers_dir: å­˜æ”¾PDFè®ºæ–‡çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆé»˜è®¤: papersï¼‰
            output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: outputï¼‰
            
        Returns:
            æ‰€æœ‰ç”Ÿæˆçš„åˆ†ææŠ¥å‘Šè·¯å¾„åˆ—è¡¨
        """
        papers_path = Path(papers_dir)
        output_path = Path(output_dir)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not papers_path.exists():
            papers_path.mkdir(parents=True, exist_ok=True)
            print(f"å·²åˆ›å»ºè®ºæ–‡æ–‡ä»¶å¤¹: {papers_path}")
        
        if not output_path.exists():
            output_path.mkdir(parents=True, exist_ok=True)
            print(f"å·²åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹: {output_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
        pdf_files = list(papers_path.glob("*.pdf"))
        
        if not pdf_files:
            print(f"\nâš ï¸  åœ¨ {papers_path} æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°PDFæ–‡ä»¶")
            print(f"è¯·å°†PDFè®ºæ–‡æ”¾å…¥ {papers_path} æ–‡ä»¶å¤¹åå†è¿è¡Œç¨‹åº")
            return []
        
        print(f"\næ‰¾åˆ° {len(pdf_files)} ç¯‡è®ºæ–‡å¾…å¤„ç†")
        print("=" * 60)
        
        results = []
        successful = 0
        failed = 0
        
        for i, pdf_file in enumerate(pdf_files, 1):
            print(f"\n{'=' * 60}")
            print(f"å¤„ç†è¿›åº¦: [{i}/{len(pdf_files)}]")
            print(f"å½“å‰è®ºæ–‡: {pdf_file.name}")
            print("=" * 60)
            
            try:
                report_path = self.process_paper(str(pdf_file), str(output_path))
                results.append(report_path)
                successful += 1
                print(f"\nâœ… æˆåŠŸ: {pdf_file.name}")
            except Exception as e:
                failed += 1
                print(f"\nâŒ å¤±è´¥: {pdf_file.name}")
                print(f"é”™è¯¯ä¿¡æ¯: {e}")
                import traceback
                traceback.print_exc()
        
        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 60)
        print("æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print("=" * 60)
        print(f"æ€»è®¡: {len(pdf_files)} ç¯‡è®ºæ–‡")
        print(f"æˆåŠŸ: {successful} ç¯‡")
        print(f"å¤±è´¥: {failed} ç¯‡")
        print(f"\næ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_path.absolute()}")
        
        return results


def main():
    """ä¸»å‡½æ•° - æ”¯æŒå•ä¸ªæ–‡ä»¶å’Œæ‰¹é‡å¤„ç†"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="è®ºæ–‡é˜…è¯»Agent - è‡ªåŠ¨æ‰¹é‡åˆ†æpapersæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰è®ºæ–‡",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æ‰¹é‡å¤„ç†papersæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰è®ºæ–‡ï¼ˆæ¨èï¼‰
  python main.py
  
  # æ‰¹é‡å¤„ç†ï¼Œä½¿ç”¨Gemini
  python main.py --provider gemini
  
  # å¤„ç†å•ä¸ªPDFæ–‡ä»¶
  python main.py --single paper.pdf
  
  # æŒ‡å®šè‡ªå®šä¹‰æ–‡ä»¶å¤¹
  python main.py --papers-dir ./my_papers --output-dir ./my_output
        """
    )
    
    # æ¨¡å¼é€‰æ‹©
    parser.add_argument("--single", metavar="PDF_FILE", 
                        help="å•æ–‡ä»¶æ¨¡å¼ï¼šå¤„ç†æŒ‡å®šçš„PDFæ–‡ä»¶")
    
    # æ‰¹é‡å¤„ç†å‚æ•°
    parser.add_argument("--papers-dir", default="papers",
                        help="è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„ (é»˜è®¤: papers)")
    parser.add_argument("--output-dir", default="output",
                        help="è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: output)")
    
    # LLMé…ç½®
    parser.add_argument("--provider", choices=["openai", "gemini"], default="openai",
                        help="LLMæä¾›å•† (é»˜è®¤: openai)")
    parser.add_argument("--model", help="æ¨¡å‹åç§° (å¦‚: gpt-5, gemini-pro)")
    parser.add_argument("--api-key", help="APIå¯†é’¥ (ä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®)")
    
    # PDFè½¬æ¢é…ç½®
    parser.add_argument("--no-mineru", action="store_true",
                        help="ä¸ä½¿ç”¨MinerU APIï¼Œæ”¹ç”¨pymupdf4llmå¿«é€Ÿæ¨¡å¼ï¼ˆå›¾ç‰‡å…¬å¼æ”¯æŒæœ‰é™ï¼‰")
    
    args = parser.parse_args()
    
    # å‡†å¤‡LLMå‚æ•°
    llm_kwargs = {}
    if args.api_key:
        llm_kwargs["api_key"] = args.api_key
    if args.model:
        llm_kwargs["model"] = args.model
    
    # åˆ›å»ºAgent
    try:
        print("\nåˆå§‹åŒ–è®ºæ–‡é˜…è¯»Agent...")
        print(f"LLMæä¾›å•†: {args.provider}")
        if args.model:
            print(f"æ¨¡å‹: {args.model}")
        
        # é»˜è®¤ä½¿ç”¨MinerUï¼Œé™¤éæŒ‡å®š--no-mineru
        use_mineru = not args.no_mineru
        if use_mineru:
            print(f"PDFè½¬æ¢: MinerU APIï¼ˆå®Œç¾æ”¯æŒå›¾ç‰‡å’Œå…¬å¼ï¼‰")
        else:
            print(f"PDFè½¬æ¢: pymupdf4llmï¼ˆå¿«é€Ÿæ¨¡å¼ï¼Œå›¾ç‰‡å…¬å¼æ”¯æŒæœ‰é™ï¼‰")
        
        agent = PaperReadingAgent(llm_provider=args.provider, use_mineru=use_mineru, **llm_kwargs)
        
        # åˆ¤æ–­æ˜¯å•æ–‡ä»¶æ¨¡å¼è¿˜æ˜¯æ‰¹é‡å¤„ç†æ¨¡å¼
        if args.single:
            # å•æ–‡ä»¶æ¨¡å¼
            print(f"\nğŸ“„ å•æ–‡ä»¶æ¨¡å¼")
            agent.process_paper(args.single, args.output_dir)
        else:
            # æ‰¹é‡å¤„ç†æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            print(f"\nğŸ“š æ‰¹é‡å¤„ç†æ¨¡å¼")
            print(f"è®ºæ–‡æ–‡ä»¶å¤¹: {Path(args.papers_dir).absolute()}")
            print(f"è¾“å‡ºæ–‡ä»¶å¤¹: {Path(args.output_dir).absolute()}")
            agent.batch_process_papers(args.papers_dir, args.output_dir)
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())

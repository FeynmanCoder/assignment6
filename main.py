"""
è®ºæ–‡é˜…è¯»Agent - ç”¨äºåˆ†æè®ºæ–‡å¹¶å­¦ä¹ è®ºæ–‡å†™ä½œ
æ”¯æŒå¤šç§LLMæä¾›å•†ï¼ˆOpenAIã€Geminiç­‰ï¼‰
"""

import os
from typing import Optional, List, Dict
from abc import ABC, abstractmethod
import json
from pathlib import Path


class LLMProvider(ABC):
    """LLMæä¾›å•†çš„æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤"""
        pass


class OpenAIProvider(LLMProvider):
    """OpenAI (ChatGPT) æä¾›å•†"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4"):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.model = model
        if not self.api_key:
            raise ValueError("éœ€è¦æä¾›OpenAI APIå¯†é’¥")
        
        try:
            from openai import OpenAI
            self.client = OpenAI(api_key=self.api_key)
        except ImportError:
            raise ImportError("è¯·å®‰è£…openaiåº“: pip install openai")
    
    def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """å‘é€æ¶ˆæ¯åˆ°OpenAIå¹¶è·å–å›å¤"""
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            **kwargs
        )
        return response.choices[0].message.content


class GeminiProvider(LLMProvider):
    """Google Gemini æä¾›å•†"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gemini-pro"):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        self.model = model
        if not self.api_key:
            raise ValueError("éœ€è¦æä¾›Gemini APIå¯†é’¥")
        
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            self.client = genai.GenerativeModel(self.model)
        except ImportError:
            raise ImportError("è¯·å®‰è£…google-generativeaiåº“: pip install google-generativeai")
    
    def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """å‘é€æ¶ˆæ¯åˆ°Geminiå¹¶è·å–å›å¤"""
        # å°†OpenAIæ ¼å¼çš„æ¶ˆæ¯è½¬æ¢ä¸ºGeminiæ ¼å¼
        prompt_parts = []
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            if role == "system":
                prompt_parts.append(f"System: {content}")
            elif role == "user":
                prompt_parts.append(f"User: {content}")
            elif role == "assistant":
                prompt_parts.append(f"Assistant: {content}")
        
        prompt = "\n\n".join(prompt_parts)
        response = self.client.generate_content(prompt)
        return response.text


class PDFConverter:
    """å°†PDFè½¬æ¢ä¸ºMarkdownçš„è½¬æ¢å™¨"""
    
    def __init__(self):
        pass
    
    def convert_to_markdown(self, pdf_path: str, output_dir: Optional[str] = None) -> str:
        """
        å°†PDFè½¬æ¢ä¸ºMarkdown
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨PDFåŒç›®å½•
            
        Returns:
            è½¬æ¢åçš„markdownæ–‡ä»¶è·¯å¾„
        """
        try:
            import pymupdf4llm
        except ImportError:
            raise ImportError("è¯·å®‰è£…pymupdf4llmåº“: pip install pymupdf4llm")
        
        pdf_path = Path(pdf_path)
        if not pdf_path.exists():
            raise FileNotFoundError(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        
        # è½¬æ¢PDFåˆ°markdown
        md_text = pymupdf4llm.to_markdown(str(pdf_path))
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if output_dir:
            output_path = Path(output_dir) / f"{pdf_path.stem}.md"
            output_path.parent.mkdir(parents=True, exist_ok=True)
        else:
            output_path = pdf_path.with_suffix('.md')
        
        # ä¿å­˜markdownæ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(md_text)
        
        print(f"PDFå·²è½¬æ¢ä¸ºMarkdown: {output_path}")
        return str(output_path)


class PaperAnalyzer:
    """è®ºæ–‡åˆ†æå™¨ - æ ¸å¿ƒç±»"""
    
    # è®ºæ–‡åˆ†æé—®é¢˜æ¨¡æ¿
    ANALYSIS_QUESTIONS = [
        {
            "category": "åŸºæœ¬ä¿¡æ¯",
            "questions": [
                "è¿™ç¯‡è®ºæ–‡å‘è¡¨åœ¨ä»€ä¹ˆå¹³å°ï¼ˆæœŸåˆŠæˆ–ä¼šè®®ï¼‰ï¼Ÿè¯¥å¹³å°åœ¨è¯¥é¢†åŸŸçš„æƒå¨æ€§å¦‚ä½•ï¼Ÿ",
                "è¿™ç¯‡è®ºæ–‡å±äºä»€ä¹ˆç ”ç©¶é¢†åŸŸï¼Ÿä¸»è¦ç ”ç©¶æ–¹å‘æ˜¯ä»€ä¹ˆï¼Ÿ",
                "è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦åˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿä¸ç°æœ‰å·¥ä½œç›¸æ¯”æœ‰å“ªäº›çªç ´ï¼Ÿ",
            ]
        },
        {
            "category": "è®ºæ–‡ç»“æ„ä¸å†™ä½œ",
            "questions": [
                "è¿™ç¯‡è®ºæ–‡å±•ç°äº†ç ”ç©¶å·¥ä½œçš„å“ªäº›æ–¹é¢ï¼ˆå¦‚é—®é¢˜å®šä¹‰ã€æ–¹æ³•è®¾è®¡ã€å®éªŒéªŒè¯ã€ç»“æœåˆ†æç­‰ï¼‰ï¼Ÿ",
                "ä½œè€…æ˜¯å¦‚ä½•å®‰æ’è¿™äº›æ–¹é¢çš„å…ˆåé¡ºåºçš„ï¼Ÿå®ƒä»¬ä¹‹é—´çš„é€»è¾‘å…³è”æ˜¯å¦‚ä½•æ’å¸ƒçš„ï¼Ÿ",
                "è®ºæ–‡æ¯ä¸ªç« èŠ‚çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿç« èŠ‚ä¹‹é—´å¦‚ä½•è¿‡æ¸¡å’Œè¡”æ¥ï¼Ÿ",
                "è®ºæ–‡çš„æ‘˜è¦å’Œç»“è®ºåˆ†åˆ«å¼ºè°ƒäº†å“ªäº›å†…å®¹ï¼Ÿå®ƒä»¬å¦‚ä½•å‘¼åº”ï¼Ÿ",
            ]
        },
        {
            "category": "å›¾è¡¨åˆ†æ",
            "questions": [
                "è®ºæ–‡åŒ…å«å“ªäº›å›¾ç‰‡å’Œè¡¨æ ¼ï¼Ÿæ¯ä¸ªå›¾è¡¨åˆ†åˆ«ä»‹ç»äº†è®ºæ–‡å·¥ä½œçš„å“ªäº›æ–¹é¢ï¼Ÿ",
                "è¿™äº›å›¾è¡¨åœ¨è®ºæ–‡ä¸­çš„ä½ç½®å¦‚ä½•å®‰æ’ï¼Ÿå®ƒä»¬å¦‚ä½•ä¸æ–‡å­—å†…å®¹ç›¸å…³è”ï¼Ÿ",
                "å“ªäº›å›¾è¡¨æœ€èƒ½ä½“ç°è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®å’Œåˆ›æ–°ç‚¹ï¼Ÿ",
                "å›¾è¡¨çš„è®¾è®¡ï¼ˆå¦‚é…è‰²ã€å¸ƒå±€ã€æ ‡æ³¨ï¼‰æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿå®ƒä»¬å¦‚ä½•å¸®åŠ©è¯»è€…ç†è§£å†…å®¹ï¼Ÿ",
            ]
        },
        {
            "category": "å†™ä½œå»ºè®®",
            "questions": [
                "å¦‚æœæˆ‘è¦å‘è¡¨ç±»ä¼¼çš„å·¥ä½œï¼Œåº”è¯¥å¦‚ä½•ç»„ç»‡è®ºæ–‡ç»“æ„ï¼Ÿ",
                "æˆ‘åº”è¯¥åœ¨è®ºæ–‡ä¸­é‡ç‚¹å‘ˆç°å“ªäº›å·¥ä½œå†…å®¹ï¼Ÿå“ªäº›å†…å®¹éœ€è¦è¯¦ç»†æè¿°ï¼Œå“ªäº›å¯ä»¥ç®€ç•¥ï¼Ÿ",
                "æˆ‘åº”è¯¥æŠŠå“ªäº›å·¥ä½œé€šè¿‡å›¾ç‰‡æˆ–è¡¨æ ¼å‘ˆç°å‡ºæ¥ï¼Ÿå¦‚ä½•è®¾è®¡è¿™äº›å›¾è¡¨ï¼Ÿ",
                "è®ºæ–‡çš„è¯­è¨€è¡¨è¾¾æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿå¦‚ä½•ä¿æŒå­¦æœ¯æ€§çš„åŒæ—¶æé«˜å¯è¯»æ€§ï¼Ÿ",
                "è¿™ç¯‡è®ºæ–‡åœ¨å†™ä½œä¸Šæœ‰å“ªäº›å€¼å¾—å­¦ä¹ çš„åœ°æ–¹ï¼Ÿåˆæœ‰å“ªäº›å¯ä»¥æ”¹è¿›çš„åœ°æ–¹ï¼Ÿ",
            ]
        },
        {
            "category": "æ·±åº¦æ€è€ƒ",
            "questions": [
                "è¿™ç¯‡è®ºæ–‡è§£å†³äº†ä»€ä¹ˆæ ¸å¿ƒé—®é¢˜ï¼Ÿä¸ºä»€ä¹ˆè¿™ä¸ªé—®é¢˜é‡è¦ï¼Ÿ",
                "è®ºæ–‡çš„æ–¹æ³•è®ºæœ‰ä»€ä¹ˆç‹¬ç‰¹ä¹‹å¤„ï¼Ÿä¸ºä»€ä¹ˆä½œè€…é€‰æ‹©è¿™ç§æ–¹æ³•ï¼Ÿ",
                "å®éªŒè®¾è®¡å¦‚ä½•éªŒè¯è®ºæ–‡çš„æ ¸å¿ƒå‡è®¾ï¼Ÿå®éªŒçš„å®Œæ•´æ€§å’Œè¯´æœåŠ›å¦‚ä½•ï¼Ÿ",
                "è®ºæ–‡çš„å±€é™æ€§æ˜¯ä»€ä¹ˆï¼Ÿæœªæ¥å¯èƒ½çš„ç ”ç©¶æ–¹å‘æœ‰å“ªäº›ï¼Ÿ",
                "è¿™ç¯‡è®ºæ–‡å¯¹æˆ‘è‡ªå·±çš„ç ”ç©¶æœ‰ä»€ä¹ˆå¯å‘ï¼Ÿ",
            ]
        }
    ]
    
    def __init__(self, llm_provider: LLMProvider):
        self.llm = llm_provider
        self.analysis_results = {}
    
    def analyze_paper(self, markdown_path: str) -> Dict[str, any]:
        """
        åˆ†æè®ºæ–‡å¹¶å›ç­”æ‰€æœ‰é—®é¢˜
        
        Args:
            markdown_path: è®ºæ–‡markdownæ–‡ä»¶è·¯å¾„
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # è¯»å–è®ºæ–‡å†…å®¹
        with open(markdown_path, 'r', encoding='utf-8') as f:
            paper_content = f.read()
        
        print("å¼€å§‹åˆ†æè®ºæ–‡...")
        results = {
            "paper_path": markdown_path,
            "categories": []
        }
        
        # å¯¹æ¯ä¸ªç±»åˆ«çš„é—®é¢˜è¿›è¡Œåˆ†æ
        for category_info in self.ANALYSIS_QUESTIONS:
            category = category_info["category"]
            questions = category_info["questions"]
            
            print(f"\nåˆ†æç±»åˆ«: {category}")
            category_result = {
                "category": category,
                "qa_pairs": []
            }
            
            for i, question in enumerate(questions, 1):
                print(f"  é—®é¢˜ {i}/{len(questions)}: {question[:50]}...")
                
                # æ„å»ºæç¤ºè¯
                messages = [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å­¦æœ¯è®ºæ–‡å†™ä½œä¸“å®¶ï¼Œæ“…é•¿åˆ†æè®ºæ–‡ç»“æ„å’Œå†™ä½œæŠ€å·§ã€‚"
                    },
                    {
                        "role": "user",
                        "content": f"""è¯·ä»”ç»†é˜…è¯»ä»¥ä¸‹è®ºæ–‡å†…å®¹ï¼Œå¹¶å›ç­”é—®é¢˜ã€‚

è®ºæ–‡å†…å®¹ï¼š
{paper_content}

é—®é¢˜ï¼š{question}

è¯·æä¾›è¯¦ç»†ã€ä¸“ä¸šçš„å›ç­”ï¼Œå¹¶ç»™å‡ºå…·ä½“çš„ä¾‹å­å’Œåˆ†æã€‚"""
                    }
                ]
                
                # è·å–LLMå›ç­”
                answer = self.llm.chat(messages)
                
                category_result["qa_pairs"].append({
                    "question": question,
                    "answer": answer
                })
            
            results["categories"].append(category_result)
        
        self.analysis_results = results
        return results
    
    def save_analysis_report(self, output_path: str) -> str:
        """
        å°†åˆ†æç»“æœä¿å­˜ä¸ºMarkdownæŠ¥å‘Š
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if not self.analysis_results:
            raise ValueError("æ²¡æœ‰å¯ä¿å­˜çš„åˆ†æç»“æœï¼Œè¯·å…ˆè¿è¡Œanalyze_paper()")
        
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# è®ºæ–‡åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**åˆ†æè®ºæ–‡**: {self.analysis_results['paper_path']}\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {self._get_current_time()}\n\n")
            f.write("---\n\n")
            
            for category_result in self.analysis_results["categories"]:
                category = category_result["category"]
                f.write(f"## {category}\n\n")
                
                for qa_pair in category_result["qa_pairs"]:
                    question = qa_pair["question"]
                    answer = qa_pair["answer"]
                    
                    f.write(f"### {question}\n\n")
                    f.write(f"{answer}\n\n")
                    f.write("---\n\n")
        
        print(f"\nåˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        return str(output_path)
    
    @staticmethod
    def _get_current_time() -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


class PaperReadingAgent:
    """è®ºæ–‡é˜…è¯»Agent - ä¸»å…¥å£ç±»"""
    
    def __init__(self, llm_provider: str = "openai", **llm_kwargs):
        """
        åˆå§‹åŒ–è®ºæ–‡é˜…è¯»Agent
        
        Args:
            llm_provider: LLMæä¾›å•† ("openai" æˆ– "gemini")
            **llm_kwargs: LLMæä¾›å•†çš„é¢å¤–å‚æ•°
        """
        # åˆå§‹åŒ–LLM
        if llm_provider.lower() == "openai":
            self.llm = OpenAIProvider(**llm_kwargs)
        elif llm_provider.lower() == "gemini":
            self.llm = GeminiProvider(**llm_kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {llm_provider}")
        
        # åˆå§‹åŒ–PDFè½¬æ¢å™¨å’Œè®ºæ–‡åˆ†æå™¨
        self.pdf_converter = PDFConverter()
        self.analyzer = PaperAnalyzer(self.llm)
    
    def process_paper(self, pdf_path: str, output_dir: Optional[str] = None) -> str:
        """
        å¤„ç†è®ºæ–‡çš„å®Œæ•´æµç¨‹
        
        Args:
            pdf_path: PDFè®ºæ–‡è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            åˆ†ææŠ¥å‘Šçš„è·¯å¾„
        """
        print("=" * 60)
        print("è®ºæ–‡é˜…è¯»Agent - å¼€å§‹å¤„ç†")
        print("=" * 60)
        
        # æ­¥éª¤1: è½¬æ¢PDFåˆ°Markdown
        print("\næ­¥éª¤1: è½¬æ¢PDFåˆ°Markdown...")
        markdown_path = self.pdf_converter.convert_to_markdown(pdf_path, output_dir)
        
        # æ­¥éª¤2: åˆ†æè®ºæ–‡
        print("\næ­¥éª¤2: åˆ†æè®ºæ–‡...")
        self.analyzer.analyze_paper(markdown_path)
        
        # æ­¥éª¤3: ç”ŸæˆæŠ¥å‘Š
        print("\næ­¥éª¤3: ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        pdf_name = Path(pdf_path).stem
        if output_dir:
            report_path = Path(output_dir) / f"{pdf_name}_analysis.md"
        else:
            report_path = Path(pdf_path).parent / f"{pdf_name}_analysis.md"
        
        report_path = self.analyzer.save_analysis_report(str(report_path))
        
        print("\n" + "=" * 60)
        print("å¤„ç†å®Œæˆï¼")
        print("=" * 60)
        print(f"Markdownæ–‡ä»¶: {markdown_path}")
        print(f"åˆ†ææŠ¥å‘Š: {report_path}")
        
        return report_path
    
    def batch_process_papers(self, papers_dir: str = "papers", output_dir: str = "output") -> List[str]:
        """
        æ‰¹é‡å¤„ç†papersæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰PDFè®ºæ–‡
        
        Args:
            papers_dir: å­˜æ”¾PDFè®ºæ–‡çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆé»˜è®¤: papersï¼‰
            output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: outputï¼‰
            
        Returns:
            æ‰€æœ‰ç”Ÿæˆçš„åˆ†ææŠ¥å‘Šè·¯å¾„åˆ—è¡¨
        """
        papers_path = Path(papers_dir)
        output_path = Path(output_dir)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not papers_path.exists():
            papers_path.mkdir(parents=True, exist_ok=True)
            print(f"å·²åˆ›å»ºè®ºæ–‡æ–‡ä»¶å¤¹: {papers_path}")
        
        if not output_path.exists():
            output_path.mkdir(parents=True, exist_ok=True)
            print(f"å·²åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹: {output_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
        pdf_files = list(papers_path.glob("*.pdf"))
        
        if not pdf_files:
            print(f"\nâš ï¸  åœ¨ {papers_path} æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°PDFæ–‡ä»¶")
            print(f"è¯·å°†PDFè®ºæ–‡æ”¾å…¥ {papers_path} æ–‡ä»¶å¤¹åå†è¿è¡Œç¨‹åº")
            return []
        
        print(f"\næ‰¾åˆ° {len(pdf_files)} ç¯‡è®ºæ–‡å¾…å¤„ç†")
        print("=" * 60)
        
        results = []
        successful = 0
        failed = 0
        
        for i, pdf_file in enumerate(pdf_files, 1):
            print(f"\n{'=' * 60}")
            print(f"å¤„ç†è¿›åº¦: [{i}/{len(pdf_files)}]")
            print(f"å½“å‰è®ºæ–‡: {pdf_file.name}")
            print("=" * 60)
            
            try:
                report_path = self.process_paper(str(pdf_file), str(output_path))
                results.append(report_path)
                successful += 1
                print(f"\nâœ… æˆåŠŸ: {pdf_file.name}")
            except Exception as e:
                failed += 1
                print(f"\nâŒ å¤±è´¥: {pdf_file.name}")
                print(f"é”™è¯¯ä¿¡æ¯: {e}")
                import traceback
                traceback.print_exc()
        
        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 60)
        print("æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print("=" * 60)
        print(f"æ€»è®¡: {len(pdf_files)} ç¯‡è®ºæ–‡")
        print(f"æˆåŠŸ: {successful} ç¯‡")
        print(f"å¤±è´¥: {failed} ç¯‡")
        print(f"\næ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_path.absolute()}")
        
        return results


def main():
    """ä¸»å‡½æ•° - æ”¯æŒå•ä¸ªæ–‡ä»¶å’Œæ‰¹é‡å¤„ç†"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="è®ºæ–‡é˜…è¯»Agent - è‡ªåŠ¨æ‰¹é‡åˆ†æpapersæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰è®ºæ–‡",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æ‰¹é‡å¤„ç†papersæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰è®ºæ–‡ï¼ˆæ¨èï¼‰
  python main.py
  
  # æ‰¹é‡å¤„ç†ï¼Œä½¿ç”¨Gemini
  python main.py --provider gemini
  
  # å¤„ç†å•ä¸ªPDFæ–‡ä»¶
  python main.py --single paper.pdf
  
  # æŒ‡å®šè‡ªå®šä¹‰æ–‡ä»¶å¤¹
  python main.py --papers-dir ./my_papers --output-dir ./my_output
        """
    )
    
    # æ¨¡å¼é€‰æ‹©
    parser.add_argument("--single", metavar="PDF_FILE", 
                        help="å•æ–‡ä»¶æ¨¡å¼ï¼šå¤„ç†æŒ‡å®šçš„PDFæ–‡ä»¶")
    
    # æ‰¹é‡å¤„ç†å‚æ•°
    parser.add_argument("--papers-dir", default="papers",
                        help="è®ºæ–‡æ–‡ä»¶å¤¹è·¯å¾„ (é»˜è®¤: papers)")
    parser.add_argument("--output-dir", default="output",
                        help="è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: output)")
    
    # LLMé…ç½®
    parser.add_argument("--provider", choices=["openai", "gemini"], default="openai",
                        help="LLMæä¾›å•† (é»˜è®¤: openai)")
    parser.add_argument("--model", help="æ¨¡å‹åç§° (å¦‚: gpt-4, gemini-pro)")
    parser.add_argument("--api-key", help="APIå¯†é’¥ (ä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®)")
    
    args = parser.parse_args()
    
    # å‡†å¤‡LLMå‚æ•°
    llm_kwargs = {}
    if args.api_key:
        llm_kwargs["api_key"] = args.api_key
    if args.model:
        llm_kwargs["model"] = args.model
    
    # åˆ›å»ºAgent
    try:
        print("\nåˆå§‹åŒ–è®ºæ–‡é˜…è¯»Agent...")
        print(f"LLMæä¾›å•†: {args.provider}")
        if args.model:
            print(f"æ¨¡å‹: {args.model}")
        
        agent = PaperReadingAgent(llm_provider=args.provider, **llm_kwargs)
        
        # åˆ¤æ–­æ˜¯å•æ–‡ä»¶æ¨¡å¼è¿˜æ˜¯æ‰¹é‡å¤„ç†æ¨¡å¼
        if args.single:
            # å•æ–‡ä»¶æ¨¡å¼
            print(f"\nğŸ“„ å•æ–‡ä»¶æ¨¡å¼")
            agent.process_paper(args.single, args.output_dir)
        else:
            # æ‰¹é‡å¤„ç†æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            print(f"\nğŸ“š æ‰¹é‡å¤„ç†æ¨¡å¼")
            print(f"è®ºæ–‡æ–‡ä»¶å¤¹: {Path(args.papers_dir).absolute()}")
            print(f"è¾“å‡ºæ–‡ä»¶å¤¹: {Path(args.output_dir).absolute()}")
            agent.batch_process_papers(args.papers_dir, args.output_dir)
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
